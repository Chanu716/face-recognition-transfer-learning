{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c0c944",
   "metadata": {},
   "source": [
    "### Face Recognition with Transfer Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbf4c99",
   "metadata": {},
   "source": [
    "Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05595267",
   "metadata": {},
   "source": [
    "Load LFW Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a9159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset (resize face images to 160x160 for FaceNet style)\n",
    "lfw = fetch_lfw_people(min_faces_per_person=20, resize=0.5)\n",
    "\n",
    "print(\"Dataset size:\", lfw.images.shape)   # (n_samples, h, w)\n",
    "print(\"Number of classes:\", len(lfw.target_names))\n",
    "\n",
    "# Example image\n",
    "plt.imshow(lfw.images[0], cmap=\"gray\")\n",
    "plt.title(lfw.target_names[lfw.target[0]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ebe801",
   "metadata": {},
   "source": [
    " Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Optimized Transformation pipeline (Smaller images for speed)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((64, 64)),  # Much smaller for faster training\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),  # Reduced augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((64, 64)),  # Matching smaller size\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "\n",
    "# Apply transform\n",
    "X = []\n",
    "for img in lfw.images:\n",
    "    # Convert numpy array to PIL Image and apply train_transform\n",
    "    X.append(train_transform(img))\n",
    "\n",
    "X = torch.stack(X)  # shape: (n_samples, 3, 160, 160)\n",
    "y = torch.tensor(lfw.target)\n",
    "\n",
    "print(\"Processed dataset:\", X.shape, y.shape)\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f98e53",
   "metadata": {},
   "source": [
    "Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa015fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split indices\n",
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(len(X)), test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Train and test tensors\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "print(\"Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Larger batch size for faster training (if you have enough memory)\n",
    "batch_size = 64  # Increased for efficiency\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f967b9",
   "metadata": {},
   "source": [
    "Basic CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be722e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimized CNN Architecture (Faster Training)\n",
    "class FaceCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FaceCNN, self).__init__()\n",
    "        # Simplified architecture for faster training\n",
    "        self.conv1 = nn.Conv2d(3, 64, 5, padding=2)  # Larger kernel, fewer layers\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(4, 4)  # Larger pooling for speed\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, 5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(4, 4)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.AdaptiveAvgPool2d((4, 4))  # Adaptive pooling\n",
    "        \n",
    "        # Smaller fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Efficient forward pass\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Flatten and classify\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99796977",
   "metadata": {},
   "source": [
    "Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5459b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "num_classes = len(set(y_train.numpy()))  # unique labels\n",
    "model = FaceCNN(num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.5)  # Reduce LR by half every 3 epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b467646",
   "metadata": {},
   "source": [
    "Train Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a272e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Training + Validation with Early Stopping (Optimized)\n",
    "num_epochs = 10  # Reduced epochs for faster training\n",
    "best_val_loss = float('inf')\n",
    "patience = 3  # Reduced patience for quicker stopping\n",
    "patience_counter = 0\n",
    "\n",
    "print(f\"Starting training on {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "import time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    # --------------------\n",
    "    # Training Phase\n",
    "    # --------------------\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_acc = 100. * correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # --------------------\n",
    "    # Validation Phase\n",
    "    # --------------------\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():  # no gradients in validation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_acc = 100. * correct / total\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    # --------------------\n",
    "    # Epoch Summary & Early Stopping\n",
    "    # --------------------\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] ({epoch_time:.1f}s) \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), 'best_face_model.pth')\n",
    "        print(f\"New best model saved! Val Loss: {best_val_loss:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience: {patience_counter}/{patience}\")\n",
    "        \n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a988abf4",
   "metadata": {},
   "source": [
    "Basic CNN Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8115462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for evaluation\n",
    "model.load_state_dict(torch.load('best_face_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Comprehensive evaluation with metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * sum([1 for p, l in zip(all_predictions, all_labels) if p == l]) / len(all_labels)\n",
    "print(f\"Final Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Classification report (precision, recall, F1-score)\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(all_labels, all_predictions, \n",
    "                          target_names=[lfw.target_names[i] for i in range(len(lfw.target_names))]))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[lfw.target_names[i] for i in range(len(lfw.target_names))],\n",
    "            yticklabels=[lfw.target_names[i] for i in range(len(lfw.target_names))])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c70680",
   "metadata": {},
   "source": [
    "Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0323435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample predictions visualization\n",
    "import random\n",
    "\n",
    "def show_sample_predictions(model, test_loader, device, num_samples=8):\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a random batch\n",
    "    dataiter = iter(test_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "    \n",
    "    # Select random samples\n",
    "    indices = random.sample(range(len(images)), min(num_samples, len(images)))\n",
    "    \n",
    "    # Plot samples\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        img = images[idx].cpu()\n",
    "        # Denormalize image for display\n",
    "        img = img * 0.5 + 0.5  # Reverse normalization\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        \n",
    "        # Convert to numpy and transpose for matplotlib\n",
    "        img_np = img.permute(1, 2, 0).numpy()\n",
    "        \n",
    "        # Get prediction confidence\n",
    "        confidence = probabilities[idx][predicted[idx]].item() * 100\n",
    "        \n",
    "        # Plot\n",
    "        axes[i].imshow(img_np)\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        true_label = lfw.target_names[labels[idx]]\n",
    "        pred_label = lfw.target_names[predicted[idx]]\n",
    "        \n",
    "        color = 'green' if labels[idx] == predicted[idx] else 'red'\n",
    "        axes[i].set_title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%', \n",
    "                         color=color, fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show sample predictions\n",
    "show_sample_predictions(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f3261",
   "metadata": {},
   "source": [
    "Transfer Learning with ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78bb1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create proper ImageNet transforms for ResNet18\n",
    "imagenet_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),  # ResNet standard size\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet values\n",
    "])\n",
    "\n",
    "# Create new dataset with proper transforms\n",
    "print(\"Creating ImageNet-normalized dataset...\")\n",
    "X_corrected = []\n",
    "for img in lfw.images:\n",
    "    X_corrected.append(imagenet_transform(img))\n",
    "\n",
    "X_corrected = torch.stack(X_corrected)\n",
    "print(f\"Corrected dataset shape: {X_corrected.shape}\")\n",
    "\n",
    "# Create corrected train/test split\n",
    "X_train_corrected, X_test_corrected = X_corrected[train_idx], X_corrected[test_idx]\n",
    "\n",
    "# New DataLoaders with corrected data\n",
    "train_dataset_corrected = TensorDataset(X_train_corrected, y_train)\n",
    "test_dataset_corrected = TensorDataset(X_test_corrected, y_test)\n",
    "\n",
    "train_loader_corrected = DataLoader(train_dataset_corrected, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader_corrected = DataLoader(test_dataset_corrected, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"‚úÖ Dataset ready for transfer learning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5b206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning Model with ResNet18\n",
    "import torchvision.models as models\n",
    "\n",
    "class ImprovedTransferFaceCNN(nn.Module):\n",
    "    def __init__(self, num_classes=62):\n",
    "        super(ImprovedTransferFaceCNN, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet18\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Freeze early layers\n",
    "        for i, (name, param) in enumerate(self.backbone.named_parameters()):\n",
    "            if i < 30:\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace classifier with custom head\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Create and setup model\n",
    "improved_transfer_model = ImprovedTransferFaceCNN(num_classes=len(lfw.target_names)).to(device)\n",
    "improved_optimizer = optim.Adam(improved_transfer_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "improved_scheduler = optim.lr_scheduler.StepLR(improved_optimizer, step_size=3, gamma=0.5)\n",
    "\n",
    "print(\"‚úÖ Transfer learning model ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a009e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Transfer Learning Model\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(\"üöÄ Training Transfer Learning Model...\")\n",
    "\n",
    "# Training parameters\n",
    "improved_epochs = 8\n",
    "best_improved_val_acc = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(improved_epochs):\n",
    "    # Training Phase\n",
    "    improved_transfer_model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader_corrected):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        improved_optimizer.zero_grad()\n",
    "        output = improved_transfer_model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        improved_optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        train_total += target.size(0)\n",
    "        train_correct += (predicted == target).sum().item()\n",
    "    \n",
    "    # Validation Phase\n",
    "    improved_transfer_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader_corrected:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = improved_transfer_model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            val_total += target.size(0)\n",
    "            val_correct += (predicted == target).sum().item()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_loss /= len(train_loader_corrected)\n",
    "    train_acc = 100. * train_correct / train_total\n",
    "    val_loss /= len(test_loader_corrected)\n",
    "    val_acc = 100. * val_correct / val_total\n",
    "    \n",
    "    improved_scheduler.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1:2d}/{improved_epochs} | '\n",
    "          f'Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_improved_val_acc:\n",
    "        best_improved_val_acc = val_acc\n",
    "        torch.save(improved_transfer_model.state_dict(), 'best_improved_transfer_model.pth')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nüéØ Best Validation Accuracy: {best_improved_val_acc:.2f}%\")\n",
    "print(f\"Training Time: {total_time:.1f} seconds\")\n",
    "\n",
    "# Load best model\n",
    "improved_transfer_model.load_state_dict(torch.load('best_improved_transfer_model.pth'))\n",
    "print(\"‚úÖ Best model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c4f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model Evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "improved_transfer_model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader_corrected:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = improved_transfer_model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        \n",
    "        test_total += target.size(0)\n",
    "        test_correct += (predicted == target).sum().item()\n",
    "        \n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "final_test_accuracy = 100. * test_correct / test_total\n",
    "print(f\"üéØ Final Test Accuracy: {final_test_accuracy:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìã Classification Report:\")\n",
    "print(classification_report(all_targets, all_predictions, target_names=lfw.target_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Predictions Visualization\n",
    "def show_improved_predictions(model, test_loader, class_names, num_samples=8):\n",
    "    model.eval()\n",
    "    \n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        confidences, predicted = torch.max(probabilities, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        # Convert image back for display\n",
    "        img = images[i].cpu()\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        img = img * std + mean\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        \n",
    "        # Convert to grayscale for display\n",
    "        img_gray = 0.299 * img[0] + 0.587 * img[1] + 0.114 * img[2]\n",
    "        \n",
    "        true_class = class_names[labels[i]]\n",
    "        pred_class = class_names[predicted[i]]\n",
    "        confidence = confidences[i].item()\n",
    "        \n",
    "        axes[i].imshow(img_gray, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        color = 'green' if predicted[i] == labels[i] else 'red'\n",
    "        status = '‚úÖ' if predicted[i] == labels[i] else '‚ùå'\n",
    "        \n",
    "        axes[i].set_title(f'{status} True: {true_class}\\nPred: {pred_class}\\nConf: {confidence:.2f}', \n",
    "                         color=color, fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Transfer Learning Model - Sample Predictions', \n",
    "                 fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    batch_accuracy = (predicted == labels).float().mean().item() * 100\n",
    "    print(f\"Batch Accuracy: {batch_accuracy:.1f}%\")\n",
    "    print(f\"Average Confidence: {confidences.mean().item():.3f}\")\n",
    "\n",
    "# Show predictions\n",
    "show_improved_predictions(improved_transfer_model, test_loader_corrected, lfw.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f22ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict new images (for demonstration)\n",
    "def predict_new_face(model, image_path, class_names):\n",
    "    \"\"\"\n",
    "    Predict a new face image (must be one of the 62 people from LFW dataset)\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Apply same transform as training\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "    \n",
    "    predicted_name = class_names[predicted.item()]\n",
    "    confidence_score = confidence.item()\n",
    "    \n",
    "    return predicted_name, confidence_score\n",
    "\n",
    "# Example usage (uncomment to use):\n",
    "# predicted_name, confidence = predict_new_face(improved_transfer_model, 'path/to/image.jpg', lfw.target_names)\n",
    "# print(f\"Predicted: {predicted_name} (Confidence: {confidence:.3f})\")\n",
    "\n",
    "print(\"Model ready for predictions!\")\n",
    "print(f\"Can recognize {len(lfw.target_names)} people from LFW dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
